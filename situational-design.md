Fatos: a interface de voz é centrada no usuário.Quando há uma grande mudança na interação homem-máquina, nós primeiro adotamos protocolos de design da tecnologia anterior. Eventualmente novos padrões de design florescem, mas com o tempo. Por exemplo, quando primeiro idealizamos a voz como forma de comandar o computador, ela foi utilizada como um replacement de um keyboard e cliques, em vez de já utilizar o potencial conversacional da tecnologia. O design de interfaces de voz não é somente incluir voz no aplicativo e chamar isso de experiência de voz. É preciso reimaginar a experiência inteira, por uma perspectiva voice-first. Há diferenças potentes entre o design de voz e design para telas. A saber. Ser adaptável: deixar o usuário usar as próprias palavras. Ser pessoal: individualizar toda a ação. Ser disponível: colapsar os menus e fazer com que todas as opções sejam top level. Ser relacionável: falar com o usuário, não para ele. 
**Ser adaptável- deixar o usuário usar suas próprias palavras.** Por mais que os UX designers tenham o objetivo de fazer as tecnologias mais fáceis de ser aprendidas, no final do dia o trabalho todo fica por conta do usuário. Quando se faz um design de UI, o designer que escolhe as cores, os textos, os fluxos e contrafluxos, o layout. Um exemplo é o botão ok. Cada vez que ele aparece, o usuário escaneia a página para se certificar que apertar OK traz a maior correspondência quanto à ação que ele deseja executar. Na interface de voz não existe um guia navegacional, mas também não existem limites tão claros quanto a interação usuário-máquina. Existem mil formas de um usuário concordar com o que está sendo falado, além de OK. Com base nisso, os sistemas de voz fazem uso de AUtomatic Speech Recognition e Natural Language Understanding para resolver a uterância do usuário para um comando OK. Essa NLU, no design de GUI, é o cérebro do usuário. No caso da interface de voz, a NLU é no cérebro da máquina. Aqui o papel deo designer se inverte. Em vez de ele escolher uma cor, um botão, ou uma forma de falar única que agrade á maioria dos usuários, agora é o papel do designer prover uma ampla gama de formas de falar para a NLU, de modo a atender a um grande número de usuários. Cada pessoa tem um estilo de speech, e sem os guias visuais para restringir o usuário para a uniformidade, os inputs variam grandemente. A VUI precisa considerar os muitos caminhos para um usuário chegar ao mesmo destino. A ambição da VUI é fazer com que a curva de aprendizado do usuário em usar a aplicação seja mínima ou inexistente. 
Intent = “botão”Utterances = “variações de botão”. Enquanto em um app de GUI nós teríamos o botão ok, na interface de voz o usuário tem inúmeras formas de comunicar a mesma intenção. 
**Ser pessoal: individualizar a interação inteira.** Na GUI, o conteúdo é personalizado, por exemplo as playlists de uma pessoa. Mas a interface é padrão. A interação, em VUI, também é personalizada. Isso é porque, uma interação padrão para todos os usuários passa uma ideia de se robótica e estéril, em vez de autêntica e acessível. O design para VUI precisa cumprir o difícil objetivo de ser previsível, porém diversa e prazeirosa. Uma simples implementação desse design pattern é usar random welcome. Múltiplas formas de dizer bem-vindo. As experiências mais sofisticadas de voice-first terão memória. A primeira experiência tende a ser mais verbos, porque o usuário precisa entender o escopo da experiência que você oferece, e o que ele pode fazer. Então na próxima vez o usuário não vai querer ouvir a história toda. A experiência vai ficando mais concisa e direto ao job to be done. Experiência com memória: usuário repesca ação de onde ele parou, mensagens personalizadas com dados de uso (ex: nossa, vc está malhando há 8 dias seguidos, bom trabalho!). É preciso personalizar e respeitar o trabalho que o usuário fez no passado. O usuário e o sistema criam um relacionamento dinâmico entre si. Enquanto o usuário gosta de padrões de GUI, ele tem baixa tolerância a padrões repetidos na VUI. Tem que ter predictabilidade, mas tem que ter o elemento surpresa. 
**Seja disponível. Colapse seus menus e faça todas as opções top-level.** No design GUI, os pixels estão em escassez. Então os menus são colapsados em níveis, em uma hierarquia por nível de relevância para a ação que se deseja executar. Os menus hierárquicos são mandatórios, até porque você não quer gerar cognitive load no usuário. No design de voz, os menus hierárquicos não ajudam o usuário. Na VUI todas as opções disponíveis precisam ser top level. Por exemplo, o usuário quer saber o número da conta bancária. Ele não vai perguntar login, entrar, meu banco, menu, conta corrente. Ele vai direto perguntar qual o número da minha conta. Isso não adiciona carga cognitiva porque simplesmente o usuário não consegue ver todas as opções. Enquanto os menus adicionam profundidade na GUI, eles adicionam fricção na VUI. O usuário na VUI não é obrigado a aprender a arquitetura da informação do aplicativo. 
**Seja relacionável. Fale com o usuário, não para o usuário.** GUIs são inerentemente inflexíveis. O usuário aprende a navegar para conseguir executar sua tarefa. É declarativa e inerentemente não cooperativa. É melhor quando é estática e não muda muito, para o usuário aprender aquele caminho e virar segunda natureza navegar aquele app. Uma boa VUI tem que ser cooperativa porque diálogos são cooperativos. Como o linguista Paul Grice disse em seu princípio cooperativo, os participantes de uma conversa cooperampara atingir fins conversacionais mútuos. Em uma conversa entre dois seres humanos, o significado implícito é levado em consideraçao para avançar a conversa. Por exemplo, se o usuário diz “quero comprar um cão gigante”, a interface de voz pode dizer “você quer mais um cão familiar ou de guarda”? Então, a VUI entendeu a intenção gigante e está dando algumas opções para especificar mais o diálogo. Under the hood a IA está buscando valores como {tamanho} e {temperamento} Enquanto a API espera -small, -med, -large, a IA entende que se o usuário disse “do tamanho de um pônei” ele quis dizer -large. A IA precisa compreender atividade. Por exemplo, se ela pergunta “onde voc~e gostaria de ir” e o usuario responde “quero iandar de kayak em portland” ela não vai perguntar “o que voc~e quer fazer lá”. É necessária uma ferramenta de gerenciamento de diálogo para gerenciar o estado e o fluxo da conversa. A VUI não fala sempre a mesma coisa, ela coopera com o usuário para levar aquela conversa adiante. 
State of the market. Todo trabalho em VUI basicamente é pioneiro, pois estamos tentando definir os padrões de design que darão forma ao jeito que interagimos com as máquinas no futuro. 
-Alexa Developers Rewards program. 